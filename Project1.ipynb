{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from cross_validation import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data, please wait\n",
      "Data loaded, continue!!\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "print(\"Loading Data, please wait\")\n",
    "testing_y, testing_x, ids_test = load_csv_data('data/test.csv')\n",
    "training_y, training_x, ids_train = load_csv_data('data/train.csv')\n",
    "print(\"Data loaded, continue!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the categorical training!!!!\n",
      "\n",
      "\n",
      "CLEANING DATA STAGE!!!!!!!!!!!!!\n",
      "\n",
      "The training for categorical value 0\n",
      "Removing undefined features for categorical value 0\n",
      "Removing the invalid value -999\n",
      "Replacing Outliers.\n",
      "DATA CLEAN!!!!!\n",
      "\n",
      "Building Polynomial Vectors\n",
      "Standarizing the data\n",
      "Adding vector of ones to offset\n",
      "\n",
      "CLEANING DATA STAGE!!!!!!!!!!!!!\n",
      "\n",
      "The training for categorical value 1\n",
      "Removing undefined features for categorical value 1\n",
      "Removing the invalid value -999\n",
      "Replacing Outliers.\n",
      "DATA CLEAN!!!!!\n",
      "\n",
      "Building Polynomial Vectors\n",
      "Standarizing the data\n",
      "Adding vector of ones to offset\n",
      "\n",
      "CLEANING DATA STAGE!!!!!!!!!!!!!\n",
      "\n",
      "The training for categorical value 2\n",
      "Removing undefined features for categorical value 2\n",
      "Removing the invalid value -999\n",
      "Replacing Outliers.\n",
      "DATA CLEAN!!!!!\n",
      "\n",
      "Building Polynomial Vectors\n",
      "Standarizing the data\n",
      "Adding vector of ones to offset\n",
      "\n",
      "CLEANING DATA STAGE!!!!!!!!!!!!!\n",
      "\n",
      "The training for categorical value 3\n",
      "Removing undefined features for categorical value 3\n",
      "Removing the invalid value -999\n",
      "Replacing Outliers.\n",
      "DATA CLEAN!!!!!\n",
      "\n",
      "Building Polynomial Vectors\n",
      "Standarizing the data\n",
      "Adding vector of ones to offset\n"
     ]
    }
   ],
   "source": [
    "# In the dateset, we found that the Column[22] PRI_jet_num dataset is categorical with Four categories defined.column_jet_nb = 22\n",
    "pred_y = []\n",
    "ids_pred_y = []\n",
    "column_categorical=22\n",
    "# In the paper where describes the differente features of the data, explains that different columns are invalid values\n",
    "# depending on the value of the categorical feature, so we can delete those values for the 4 different trainings\n",
    "\n",
    "#The undefined features, with first vector for the categorical value of 0, and so on.\n",
    "undefined_features = [[4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29], [4, 5, 6, 12, 22, 26, 27, 28], [22], [22]]\n",
    "\n",
    "#We will have a for loop with 4 values for the 4 categorical training\n",
    "print(\"Starting the categorical training!!!!\\n\")\n",
    "for nb_jets in range(0, 4):\n",
    "    print(\"\\nCLEANING DATA STAGE!!!!!!!!!!!!!\\n\")\n",
    "    print(\"The training for categorical value %d\" %nb_jets)\n",
    "    # We will separate the data according to the value of the categorical values for each loop in our cicle\n",
    "    test_x = testing_x[testing_x[:, column_categorical] == nb_jets]\n",
    "    test_y = testing_y[testing_x[:, column_categorical] == nb_jets]\n",
    "    id_test = ids_test[testing_x[:, column_categorical] == nb_jets]\n",
    "    train_x = training_x[training_x[:, column_categorical] == nb_jets]\n",
    "    train_y = training_y[training_x[:, column_categorical] == nb_jets]\n",
    "    id_train = ids_train[training_x[:, column_categorical] == nb_jets]\n",
    "    #Now we will remove the undefined features depending on the categorical value\n",
    "    print(\"Removing undefined features for categorical value\", nb_jets)\n",
    "    test_x = np.delete(test_x, undefined_features[nb_jets], axis=1)\n",
    "    train_x = np.delete(train_x, undefined_features[nb_jets], axis=1)\n",
    "    #Now we will remove the unvalid value of -999 by replacing the value with the mean of the column\n",
    "    print(\"Removing the invalid value -999\")\n",
    "    train_x = remove_invalid(train_x)\n",
    "    test_x = remove_invalid(test_x)\n",
    "    #Now we will replace the ourliers with the most common element of each column\n",
    "    print(\"Replacing Outliers.\")\n",
    "    train_x = remove_outliers(train_x)\n",
    "    test_x = remove_outliers(test_x)\n",
    "    #Now we will build the polynomial vectors to fit the data\n",
    "    print(\"DATA CLEAN!!!!!\\n\")\n",
    "    print(\"Building Polynomial Vectors\")\n",
    "    degree = 5\n",
    "    training_poly_x = build_poly(train_x, degree)\n",
    "    testing_poly_x = build_poly(test_x, degree)\n",
    "    #Then we need to standarize the data, first the training_x and then the\n",
    "    # testing_x with the values(mean_train,std_train) found before\n",
    "    print(\"Standarizing the data\")\n",
    "    std_training_x, mean_train, std_train = standardize(training_poly_x)\n",
    "    std_testing_x = standardize_test(testing_poly_x, mean_train, std_train)\n",
    "    #Now we will add the offset column of ones [1]\n",
    "    print(\"Adding vector of ones to offset\")\n",
    "    training_tx = np.c_[np.ones(len(train_y)), std_training_x]\n",
    "    testing_tx = np.c_[np.ones(len(test_y)), std_testing_x]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
